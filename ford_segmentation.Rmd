---
title: "Ford Ka Segmentation Exercise"
author: "Krisha Lim"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Cleaning

First we load the packages we will use for this analysis.

```{r}
pacman::p_load(dplyr, tidyverse, ggplot2, here, readxl, janitor, modelsummary, kableExtra, cluster, factoextra)
```

Next, we load the demographic data and psychographic data and merge these two files by `respondent_id`.

```{r}
dg <- read_excel(here("data", "Ford Ka (Student).xls"), 
                 sheet = "Demographic Data", 
                 skip = 6) %>%
  clean_names()

psyc <- read_excel(here("data", "Ford Ka (Student).xls"), 
                   sheet = "Psychographic Data", 
                   skip = 6) %>%
  clean_names()

ford <- left_join(dg, psyc, by = c("respondent_number"))
```

Instead of loading each reference table in the spreadsheet's Demographics Code sheet, I converted the relevant variables into a factor variable and used the code sheet's information as the levels.

```{r, echo = F}
# manually factor variables
ford$preference_group <- recode_factor(factor(ford$preference_group), 
                                     `1` = "Ka Chooser (top 3)",
                                     `2` = "Ka Non-Chooser (bottom 3)",
                                     `3` = "Middle (middle 4)")

ford$gender <- recode_factor(factor(ford$gender), 
                           `1` = "Male",
                           `2` = "Female")

ford$marital_status <- recode_factor(factor(ford$marital_status), 
                                   `1` = "Married", 
                                   `2` = "Living Together", 
                                   `3` = "Single")

ford$x1st_time_purchase <- recode_factor(factor(ford$x1st_time_purchase), 
                                       `1` = "Yes", 
                                       `2` = "No")

ford$age_category <- recode_factor(factor(ford$age_category), 
                                 `1` = "<25", 
                                 `2` = "25-29", 
                                 `3` = "30-34", 
                                 `4` = "35-39", 
                                 `5` = "40-44", 
                                 `6` = ">44")

ford$children_category <- recode_factor(factor(ford$children_category), 
                                      `0` = "0 child", 
                                      `1` = "1 child", 
                                      `2` = ">1 child")

ford$income_category <- recode_factor(factor(ford$income_category), 
                                    `1` = "<100K", 
                                    `2` = "100K-150K", 
                                    `3` = "150K-200K",
                                    `4` = "200K-250K", 
                                    `5` = "250K-300K", 
                                    `6`= ">300K")
```

# Crosstabs Analysis 

Next, we run crosstabs to check whether different demographic variables separate "Ka Choosers" from "Ka Non-Choosers". The results are in line with Student # 76174135. 

```{r, echo = F}
ct_gender <- datasummary_crosstab(preference_group ~ gender, 
                     statistic = 1 ~ Percent("row"), 
                     data = ford)

ct_marital <- datasummary_crosstab(preference_group ~ marital_status, 
                                  statistic = 1 ~ Percent("row"), 
                                  data = ford)

ct_firstcar <- datasummary_crosstab(preference_group ~ x1st_time_purchase, 
                                   statistic = 1 ~ Percent("row"), 
                                   data = ford)

ct_kids <- datasummary_crosstab(preference_group ~ children_category, 
                                    statistic = 1 ~ Percent("row"), 
                                    data = ford)

ct_income <- datasummary_crosstab(preference_group ~ income_category, 
                                statistic = 1 ~ Percent("row"), 
                                data = ford)

ct_age <- datasummary_crosstab(preference_group ~ age_category, 
                                  statistic = 1 ~ Percent("row"), 
                                  data = ford)
```

```{r, echo = F}
ct_gender
ct_marital
ct_firstcar
ct_kids
ct_income
ct_age
```

# Clustering Analysis

`set.seed(2022)` allows me to reproduce the same results, as the order of clusters change.

```{r}
ford_psyc <- select(ford, q1:q62)
set.seed(2022)
k3 <- kmeans(ford_psyc, centers = 3, nstart = 25)  
set.seed(2022)
k4 <- kmeans(ford_psyc, centers = 4, nstart = 25)  
set.seed(2022)
k5 <- kmeans(ford_psyc, centers = 5, nstart = 25)  
```

## 3 Clusters

The three clusters have the following sizes: `r k3$size`
```{r, echo = F}
k3$centers
fviz_cluster(k3, data = ford_psyc)
```

## 4 Clusters

The four clusters have the following sizes: `r k4$size`. These results replicate the numbers in the file `Ford Ka 4-Cluster Results - no variables missing`. 

```{r, echo = F}
k4$centers
fviz_cluster(k4, data = ford_psyc)
```

## 5 Clusters

The five clusters have the following sizes: `r k5$size`. **I don't get the same small cluster as noted by the students**

```{r, echo = F}
k5$centers
fviz_cluster(k5, data = ford_psyc)
```


# Optimal clusters

The **Elbow Method** suggests that 4 is the optimal number of clusters as this appears to be the bend in the graph. 

```{r}
set.seed(2022)

fviz_nbclust(ford_psyc, kmeans, method = "wss")
```

The **Silhouette Method** suggests that

```{r}
fviz_nbclust(ford_psyc, kmeans, method = "silhouette")
```

The **gap statistic method** 

```{r, message = F}
set.seed(2022)
gap_stat <- clusGap(ford_psyc, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)

fviz_gap_stat(gap_stat)
```